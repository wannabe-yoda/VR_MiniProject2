{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11748083,"sourceType":"datasetVersion","datasetId":7375098},{"sourceId":11748127,"sourceType":"datasetVersion","datasetId":7375132}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"Imports go here\"\"\"\n\nfrom transformers import ViltProcessor, ViltForQuestionAnswering\nimport torch\nfrom PIL import Image\nimport requests\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n#from word2number import w2n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:55:37.952914Z","iopub.execute_input":"2025-05-14T02:55:37.953156Z","iopub.status.idle":"2025-05-14T02:56:02.698738Z","shell.execute_reply.started":"2025-05-14T02:55:37.953132Z","shell.execute_reply":"2025-05-14T02:56:02.698136Z"}},"outputs":[{"name":"stderr","text":"2025-05-14 02:55:51.306136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747191351.490545      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747191351.540763      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\" Load CSV and split the data \"\"\"\n\n# Load the CSV file\ncsv_path = \"/kaggle/input/qna-final/qna_final.csv\"\ndf = pd.read_csv(csv_path)\n\n# Get unique Item_IDs\nunique_ids = df[\"Item_ID\"].unique()\n\n# Set random seed for reproducibility\nrandom_seed = 42\nnp.random.seed(random_seed)\n\n# Shuffle and split the unique IDs\ntrain_ids, temp_ids = train_test_split(unique_ids, test_size=0.3, random_state=random_seed)  # 70% train\nval_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=random_seed)      # 15% val, 15% test\n\n# Create train, val, and test DataFrames\ntrain_df = df[df[\"Item_ID\"].isin(train_ids)]\nval_df = df[df[\"Item_ID\"].isin(val_ids)]\ntest_df = df[df[\"Item_ID\"].isin(test_ids)]\n\nprint(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:56:52.072654Z","iopub.execute_input":"2025-05-14T02:56:52.073609Z","iopub.status.idle":"2025-05-14T02:56:52.155041Z","shell.execute_reply.started":"2025-05-14T02:56:52.073581Z","shell.execute_reply":"2025-05-14T02:56:52.154198Z"}},"outputs":[{"name":"stdout","text":"Train size: 16666, Val size: 3663, Test size: 3558\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\"\"\"Normalizing and mapping non-existing answers to semantically similar existing answers in label2id\"\"\"\n# Load the model and processor\nmodel_config_source = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\nprocessor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n\n# Text-to-number mapping (same as before)\ndef get_text_to_num_mapping():\n    text_to_num = {\n        \"zero\": \"0\", \"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\",\n        \"five\": \"5\", \"six\": \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\",\n        \"ten\": \"10\", \"eleven\": \"11\", \"twelve\": \"12\", \"thirteen\": \"13\",\n        \"fourteen\": \"14\", \"fifteen\": \"15\", \"sixteen\": \"16\", \"seventeen\": \"17\",\n        \"eighteen\": \"18\", \"nineteen\": \"19\", \"twenty\": \"20\",\n    }\n    for i in range(21, 1001):\n        text_to_num[str(i)] = str(i)\n    return text_to_num\n\ntext_to_num_map = get_text_to_num_mapping()\n\ndef normalize_answer(answer_str):\n    normalized = str(answer_str).strip().lower()\n    return text_to_num_map.get(normalized, normalized)\n\n# Create DataFrames with .copy()\ntrain_df = df[df[\"Item_ID\"].isin(train_ids)].copy()\nval_df = df[df[\"Item_ID\"].isin(val_ids)].copy()\ntest_df = df[df[\"Item_ID\"].isin(test_ids)].copy()\n\n# Add normalized answers\ntrain_df['normalized_answer'] = train_df['Answer'].apply(normalize_answer)\nval_df['normalized_answer'] = val_df['Answer'].apply(normalize_answer)\ntest_df['normalized_answer'] = test_df['Answer'].apply(normalize_answer)\n\n# Get the original label2id\noriginal_label2id = model_config_source.config.label2id\noriginal_answers = list(original_label2id.keys())\n\n# Load sentence-transformers for semantic similarity\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Load a pre-trained model for semantic embeddings\nprint(\"Loading sentence transformer model for semantic matching...\")\nsemantic_model = SentenceTransformer('all-MiniLM-L6-v2')  # A lightweight model that works well for semantic similarity\n\n# Pre-compute embeddings for all original answers\nprint(\"Computing embeddings for original vocabulary...\")\noriginal_embeddings = semantic_model.encode(original_answers, show_progress_bar=False)\n\ndef find_semantically_similar_answer(new_answer, original_answers, original_embeddings):\n    \"\"\"Find the most semantically similar answer in original_answers to new_answer\"\"\"\n    # Get embedding for the new answer\n    new_embedding = semantic_model.encode([new_answer], show_progress_bar=False)\n    \n    # Calculate cosine similarity between new answer and all original answers\n    similarities = cosine_similarity(new_embedding, original_embeddings)[0]\n    \n    # Get the index of the most similar answer\n    most_similar_idx = np.argmax(similarities)\n    similarity_score = similarities[most_similar_idx]\n    \n    return original_answers[most_similar_idx], similarity_score\n\n# Create a mapping dictionary for unseen answers\nanswer_mapping = {}\nsimilarity_scores = {}\n\nprint(\"Creating semantic mappings for unseen answers...\")\n# Process all datasets to create mappings\nfor dataset_name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n    mapped_count = 0\n    for ans in df['normalized_answer'].unique():\n        if ans not in original_label2id and ans not in answer_mapping:\n            similar_ans, score = find_semantically_similar_answer(ans, original_answers, original_embeddings)\n            answer_mapping[ans] = similar_ans\n            similarity_scores[ans] = score\n            mapped_count += 1\n    \n    print(f\"Dataset {dataset_name}: Mapped {mapped_count} unseen answers to semantically similar existing answers\")\n\n# Apply mapping to create mapped_answer column\ndef map_to_similar_answer(answer):\n    if answer in original_label2id:\n        return answer  # Already in the vocabulary\n    return answer_mapping.get(answer, answer)  # Map to similar answer if needed\n\ntrain_df['mapped_answer'] = train_df['normalized_answer'].apply(map_to_similar_answer)\nval_df['mapped_answer'] = val_df['normalized_answer'].apply(map_to_similar_answer)\ntest_df['mapped_answer'] = test_df['normalized_answer'].apply(map_to_similar_answer)\n\n# Print some statistics about the mapping\nprint(\"\\nAnswer mapping examples (with similarity scores):\")\nif answer_mapping:\n    # Sort by similarity score for better examples display\n    sorted_mappings = sorted([(k, v, similarity_scores[k]) for k, v in answer_mapping.items()], \n                            key=lambda x: x[2], reverse=True)\n    \n    for i, (new_ans, similar_ans, score) in enumerate(sorted_mappings[:10]):  # Show first 10 examples\n        print(f\"  '{new_ans}' -> '{similar_ans}' (similarity: {score:.3f})\")\n\n    if len(answer_mapping) > 10:\n        print(f\"  ... and {len(answer_mapping) - 10} more mappings\")\nelse:\n    print(\"  No mappings were created (all answers already in vocabulary)\")\n\n# --- Final Check ---\nprint(\"\\nFinal sizes:\")\nprint(f\"Train: {len(train_df)}\")\nprint(f\"Val: {len(val_df)}\")\nprint(f\"Test: {len(test_df)}\")\nprint(f\"Original vocabulary size: {len(original_label2id)}\")\nprint(f\"Total answer mappings created: {len(answer_mapping)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:56:54.660738Z","iopub.execute_input":"2025-05-14T02:56:54.661616Z","iopub.status.idle":"2025-05-14T02:57:22.820392Z","shell.execute_reply.started":"2025-05-14T02:56:54.661584Z","shell.execute_reply":"2025-05-14T02:57:22.819692Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/136k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16295b1eb51f4294b68f7962f80caf8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59acfa8e886c4f8f86d8109fdb81a263"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33607efdd2d48369e24219598f23b20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64195d4a8bc94a66acc5e595425d6729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e4e8e51b414119ae83c784e3cc45b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76fa7ecbfa7345c0874c59570700287f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3066f450273342aa8e90ed2b2e079075"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7004257e053424289b55434dfccdc94"}},"metadata":{}},{"name":"stdout","text":"Loading sentence transformer model for semantic matching...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92bd8a3ba6e478aa8b9c02a4aab1ba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db363e2c4ef4043a0f9b0832e4d0f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474927014bed47458f4d36ea86a2c6f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07151e2c4004cffb9773e79338c44e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98631330e77446a4b44a2620b621e39c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6138c40c29a842c9b932de8f8dcac154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6f0823acbe64f2081076c454209c4d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef303e39402b479d83eeedebdc076b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06607fa797e7411bbb92e2695ee08bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ed26f1be9d4e2f8467718758f7abe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d09da5906e42dd91e5faf08dcf37b2"}},"metadata":{}},{"name":"stdout","text":"Computing embeddings for original vocabulary...\nCreating semantic mappings for unseen answers...\nDataset train: Mapped 335 unseen answers to semantically similar existing answers\nDataset val: Mapped 40 unseen answers to semantically similar existing answers\nDataset test: Mapped 57 unseen answers to semantically similar existing answers\n\nAnswer mapping examples (with similarity scores):\n  'multi-colored' -> 'multi colored' (similarity: 0.977)\n  'grey' -> 'gray' (similarity: 0.968)\n  'aluminium' -> 'aluminum' (similarity: 0.960)\n  'multicolor' -> 'multicolored' (similarity: 0.950)\n  'sunsets' -> 'sunset' (similarity: 0.941)\n  '6-foot' -> '6 feet' (similarity: 0.921)\n  'almond' -> 'almonds' (similarity: 0.913)\n  '89' -> '88' (similarity: 0.913)\n  'olive' -> 'olives' (similarity: 0.906)\n  'letter' -> 'letters' (similarity: 0.902)\n  ... and 422 more mappings\n\nFinal sizes:\nTrain: 16666\nVal: 3663\nTest: 3558\nOriginal vocabulary size: 3129\nTotal answer mappings created: 432\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\"\"\"Create a custom dataset class\"\"\"\n\nclass QnADataset(Dataset):\n    def __init__(self, dataframe, image_dir, processor, label2id): # Processor is not strictly needed here anymore, but label2id is\n        self.dataframe = dataframe\n        self.image_dir = image_dir\n        # self.processor = processor # Not used directly in __getitem__ anymore\n        self.label2id = label2id\n        self.text_to_num = self.generate_text_to_num_mapping()\n\n    def generate_text_to_num_mapping(self):\n        # (Your existing generate_text_to_num_mapping method - keep as is)\n        text_to_num = {\n            \"zero\": \"0\", \"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\",\n            \"five\": \"5\", \"six\": \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\",\n            \"ten\": \"10\", \"eleven\": \"11\", \"twelve\": \"12\", \"thirteen\": \"13\",\n            \"fourteen\": \"14\", \"fifteen\": \"15\", \"sixteen\": \"16\", \"seventeen\": \"17\",\n            \"eighteen\": \"18\", \"nineteen\": \"19\", \"twenty\": \"20\",\n        }\n        for i in range(21, 1001):\n            text_to_num[str(i)] = str(i)\n        return text_to_num\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image_path = f\"{self.image_dir}/{row['Image_Path']}\"\n        question_text = row[\"Question\"]  # Keep as raw text\n        \n        # Use mapped_answer instead of Answer\n        mapped_answer = row[\"mapped_answer\"].strip().lower()\n\n        # Convert text-based numbers to numerical strings if needed\n        if mapped_answer in self.text_to_num:\n            processed_answer_str = self.text_to_num[mapped_answer]\n        else:\n            processed_answer_str = mapped_answer\n\n        # Load PIL image\n        try:\n            pil_image = Image.open(image_path).convert(\"RGB\")\n        except FileNotFoundError:\n            print(f\"Error: Image not found at {image_path}\")\n            # Handle appropriately: skip, return None, or use a placeholder\n            # For now, let's re-raise to make it obvious during debugging\n            raise\n        except Exception as e:\n            print(f\"Error loading image {image_path}: {e}\")\n            raise\n\n        # Encode the answer string to an ID\n        if processed_answer_str in self.label2id:\n            answer_id = self.label2id[processed_answer_str]\n        else:\n            # This should be less common now since we're using mapped answers\n            print(f\"Warning: Mapped answer '{processed_answer_str}' not found in label2id mapping. Item index: {idx}, Image: {row['Image_Path']}\")\n            # We'll still include error handling for robustness\n            raise ValueError(f\"Mapped answer '{processed_answer_str}' (from original '{row.get('Answer', 'N/A')}') not found in label2id mapping for image {row['Image_Path']}.\")\n\n        return {\n            \"image\": pil_image,          # Return the PIL Image object\n            \"question\": question_text,   # Return the raw question string\n            \"labels\": torch.tensor(answer_id, dtype=torch.long) # Return the label as a tensor\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:57:41.424019Z","iopub.execute_input":"2025-05-14T02:57:41.424624Z","iopub.status.idle":"2025-05-14T02:57:41.432604Z","shell.execute_reply.started":"2025-05-14T02:57:41.424599Z","shell.execute_reply":"2025-05-14T02:57:41.431938Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\"\"\" Prepare dataloaders \"\"\"\nfrom functools import partial\n\n# Use original_label2id instead of extended_label2id\nnum_labels = len(original_label2id)\n\n# Directory containing the images\nimage_dir = \"/kaggle/input/filtered-small-amazon-qna\"\n\n# Create datasets with ORIGINAL labels and dataframes containing mapped_answer column\ntrain_dataset = QnADataset(train_df, image_dir, processor, original_label2id)\nval_dataset = QnADataset(val_df, image_dir, processor, original_label2id)  # Use full val_df, not filtered\ntest_dataset = QnADataset(test_df, image_dir, processor, original_label2id)  # Use full test_df, not filtered\n\n# Collate function with original num_labels\ndef collate_fn(batch, processor, num_classes=num_labels):\n    \"\"\"ViLT-compatible collate function with one-hot encoding\"\"\"\n    # Filter out invalid entries\n    valid_batch = [\n        item for item in batch \n        if item is not None \n        and isinstance(item.get(\"image\"), Image.Image)\n        and item.get(\"question\") \n        and item.get(\"labels\") is not None\n    ]\n    \n    if not valid_batch:\n        return None\n    \n    # Process valid items\n    images = [item[\"image\"] for item in valid_batch]\n    texts = [item[\"question\"] for item in valid_batch]\n    labels = [item[\"labels\"] for item in valid_batch]  # Should be class indices\n\n    # Process through processor\n    try:\n        encoding = processor(\n            images=images,\n            text=texts,\n            return_tensors=\"pt\",\n            padding=\"longest\",\n            truncation=True,\n            max_length=512\n        )\n    except Exception as e:\n        print(f\"Skipping batch: {str(e)}\")\n        return None\n\n    # Convert labels to one-hot encoding\n    batch_size = len(labels)\n    one_hot_labels = torch.zeros(batch_size, num_classes)\n    for i, label in enumerate(labels):\n        one_hot_labels[i, label] = 1.0\n\n    encoding[\"labels\"] = one_hot_labels\n    return encoding\n\n# Create DataLoaders with proper partial binding\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=partial(collate_fn, processor=processor),  # Keyword argument binding\n    drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=16,\n    shuffle=False,\n    collate_fn=partial(collate_fn, processor=processor)  # Keyword argument binding\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=16,\n    shuffle=False,\n    collate_fn=partial(collate_fn, processor=processor)  # Keyword argument binding\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T02:57:46.291661Z","iopub.execute_input":"2025-05-14T02:57:46.291988Z","iopub.status.idle":"2025-05-14T02:57:46.301493Z","shell.execute_reply.started":"2025-05-14T02:57:46.291954Z","shell.execute_reply":"2025-05-14T02:57:46.300680Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Fine tuning part","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom tqdm import tqdm\nfrom transformers import get_linear_schedule_with_warmup\nimport torch.optim as optim\nfrom peft import LoraConfig, get_peft_model\n\n# --- Config ---\nNUM_EPOCHS    = 20\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY  = 1e-2\nWARMUP_RATIO  = 0.1       # 10% of total steps\nMAX_GRAD_NORM = 1.0\nOUTPUT_DIR    = \"/kaggle/working/vilt-lora-manual-best\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# --- Model + LoRA setup (UPDATED) ---\noriginal_model = ViltForQuestionAnswering.from_pretrained(\n    \"dandelin/vilt-b32-finetuned-vqa\",\n    # Using original vocabulary from the pretrained model\n    num_labels=len(original_label2id),\n    id2label=model_config_source.config.id2label,\n    label2id=original_label2id\n    # Removed ignore_mismatched_sizes since we're using original sizes\n)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    modules_to_save=[\"classifier\"]\n)\nmodel = get_peft_model(original_model, lora_config)\nmodel.to(device)\nmodel.print_trainable_parameters()\n\n# --- Optimizer + Scheduler + AMP Scaler ---\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=LEARNING_RATE, \n    weight_decay=WEIGHT_DECAY\n)\n\ntotal_steps   = len(train_loader) * NUM_EPOCHS\nwarmup_steps  = int(WARMUP_RATIO * total_steps)\nscheduler     = get_linear_schedule_with_warmup(\n    optimizer, warmup_steps, total_steps\n)\n\nscaler = torch.cuda.amp.GradScaler()\n\nbest_val_loss = float('inf')\npatience, patience_counter = 10, 0\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    print(f\"\\n-- Epoch {epoch}/{NUM_EPOCHS} --\")\n    t0_epoch = time.time()\n\n    # ---- TRAIN ----\n    model.train()\n    train_loss = 0.0\n    train_batches = 0\n    pbar = tqdm(train_loader, desc=\"Train\", leave=False)\n    for batch in pbar:\n        # Skip None batches\n        if batch is None:\n            continue\n            \n        batch = {k: v.to(device) for k,v in batch.items() if v is not None}\n\n        optimizer.zero_grad()\n        with torch.amp.autocast('cuda'):  # Updated to new format\n            outputs = model(**batch)\n            loss = outputs.loss\n\n        scaler.scale(loss).backward()\n        # clip grads\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        train_loss += loss.item()\n        train_batches += 1\n        pbar.set_postfix(loss=loss.item())\n\n    avg_train = train_loss / max(train_batches, 1)  # Avoid division by zero\n    \n    # ---- VALIDATION ----\n    model.eval()\n    val_loss = 0.0\n    val_batches = 0\n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc=\"Valid\", leave=False)\n        for batch in pbar:\n            # Skip None batches\n            if batch is None:\n                continue\n                \n            batch = {k: v.to(device) for k,v in batch.items() if v is not None}\n            with torch.amp.autocast('cuda'):  # Updated to new format\n                loss = model(**batch).loss\n            val_loss += loss.item()\n            val_batches += 1\n            pbar.set_postfix(loss=loss.item())\n\n    avg_val = val_loss / max(val_batches, 1)  # Avoid division by zero\n    print(f\"Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f} | Time: {(time.time()-t0_epoch):.1f}s\")\n\n    # ---- Early Stopping & Checkpointing ----\n    if avg_val < best_val_loss:\n        best_val_loss = avg_val\n        patience_counter = 0\n        print(f\" New best! Saving to {OUTPUT_DIR}\")\n        model.save_pretrained(OUTPUT_DIR)\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"Stopping early (no improvement for {patience} epochs).\")\n            break\n\nprint(\"\\n=== Training Complete ===\")\nprint(f\"Best Validation Loss: {best_val_loss:.4f}\")\nprint(f\"Best model saved at: {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T04:17:01.729031Z","iopub.execute_input":"2025-05-14T04:17:01.729893Z","iopub.status.idle":"2025-05-14T05:54:32.911831Z","shell.execute_reply.started":"2025-05-14T04:17:01.729866Z","shell.execute_reply":"2025-05-14T05:54:32.910970Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/3245674829.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 6,583,353 || all params: 124,171,890 || trainable%: 5.3018\n\n-- Epoch 1/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:05,  3.27it/s, loss=2.63]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:36<00:31,  3.28it/s, loss=1.17] ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.9718 | Val Loss: 2.2320 | Time: 498.8s\n New best! Saving to /kaggle/working/vilt-lora-manual-best\n\n-- Epoch 2/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:03,  3.38it/s, loss=2.69]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.35it/s, loss=0.946] ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.8692 | Val Loss: 2.0703 | Time: 489.7s\n New best! Saving to /kaggle/working/vilt-lora-manual-best\n\n-- Epoch 3/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:03,  3.37it/s, loss=2.82]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.31it/s, loss=1.3]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3256 | Val Loss: 2.1360 | Time: 490.2s\n\n-- Epoch 4/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:03,  3.41it/s, loss=4.44]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:30,  3.36it/s, loss=1.38]   ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9537 | Val Loss: 2.2327 | Time: 489.6s\n\n-- Epoch 5/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:02,  3.42it/s, loss=4.17]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.35it/s, loss=1.67]   ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7343 | Val Loss: 2.3835 | Time: 484.4s\n\n-- Epoch 6/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:03,  3.38it/s, loss=4.99]     ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.26it/s, loss=2.13]   ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5816 | Val Loss: 2.5106 | Time: 484.8s\n\n-- Epoch 7/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:02,  3.46it/s, loss=5.47]     ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.33it/s, loss=2.31]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4787 | Val Loss: 2.6536 | Time: 484.4s\n\n-- Epoch 8/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:02,  3.42it/s, loss=5.89]     ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.30it/s, loss=1.99]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4019 | Val Loss: 2.8437 | Time: 485.0s\n\n-- Epoch 9/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:04,  3.36it/s, loss=7.05]     ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.30it/s, loss=0.797]   ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3471 | Val Loss: 2.8858 | Time: 485.0s\n\n-- Epoch 10/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:02,  3.44it/s, loss=6.65]     ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.29it/s, loss=2.19]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2983 | Val Loss: 3.0493 | Time: 485.9s\n\n-- Epoch 11/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:02,  3.46it/s, loss=7.5]      ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.31it/s, loss=2.44]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2638 | Val Loss: 3.1226 | Time: 486.3s\n\n-- Epoch 12/20 --\n","output_type":"stream"},{"name":"stderr","text":"Valid:   6%|▌         | 14/229 [00:04<01:04,  3.33it/s, loss=7.8]      ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"Valid:  55%|█████▍    | 125/229 [00:34<00:31,  3.30it/s, loss=2.97]    ","output_type":"stream"},{"name":"stdout","text":"Skipping batch: height and width must be > 0\n","output_type":"stream"},{"name":"stderr","text":"                                                                       ","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2339 | Val Loss: 3.2616 | Time: 485.0s\nStopping early (no improvement for 10 epochs).\n\n=== Training Complete ===\nBest Validation Loss: 2.0703\nBest model saved at: /kaggle/working/vilt-lora-manual-best\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"!pip install bert-score\n!git clone https://github.com/neulab/BARTScore.git\nimport sys\nsys.path.append(\"./BARTScore\")\n# Now import\nfrom bart_score import BARTScorer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T05:56:20.541277Z","iopub.execute_input":"2025-05-14T05:56:20.542078Z","iopub.status.idle":"2025-05-14T05:58:47.480728Z","shell.execute_reply.started":"2025-05-14T05:56:20.542047Z","shell.execute_reply":"2025-05-14T05:58:47.480014Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCloning into 'BARTScore'...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"remote: Enumerating objects: 220, done.\u001b[K\nremote: Counting objects: 100% (26/26), done.\u001b[K\nremote: Compressing objects: 100% (12/12), done.\u001b[K\nremote: Total 220 (delta 18), reused 14 (delta 14), pack-reused 194 (from 1)\u001b[K\nReceiving objects: 100% (220/220), 101.98 MiB | 21.64 MiB/s, done.\nResolving deltas: 100% (47/47), done.\nUpdating files: 100% (192/192), done.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import sys\nimport time\nimport torch\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n\n# 1. Add local BARTScore code into Python’s import path\nsys.path.append(\"./BARTScore\")\n\n# 2. Semantic‐similarity imports\nfrom bert_score import score as bert_score\nfrom bart_score import BARTScorer\n\n# 3. PEFT & model imports\nfrom transformers import ViltForQuestionAnswering\nfrom peft import PeftModel\n\n# 4. Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# 5. Reload base + LoRA‐finetuned model\n#    (assumes you previously saved to OUTPUT_DIR)\nOUTPUT_DIR = \"/kaggle/working/vilt-lora-manual-best\"\nbase_model = ViltForQuestionAnswering.from_pretrained(\n    \"dandelin/vilt-b32-finetuned-vqa\",\n    num_labels=len(original_label2id),\n    id2label=model_config_source.config.id2label,\n    label2id=original_label2id,\n    ignore_mismatched_sizes=True\n)\nmodel = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\nmodel.to(device)\nmodel.eval()\n\n# 6. Accumulators\nall_pred_ids   = []\nall_true_ids   = []\nall_pred_texts = []\nall_true_texts = []\n\n# --- Start overall timer ---\nt0_overall = time.time()\n\n# 7. Inference + gather labels/texts with progress bar\nt0_loop = time.time()\nfor batch in tqdm(test_loader, desc=\"Evaluating batches\"):\n    batch = {k: v.to(device) for k, v in batch.items()}\n    outputs = model(**batch)\n    logits  = outputs.logits\n\n    # Predicted & true IDs\n    pred_ids = logits.argmax(dim=-1)\n    true_ids = batch[\"labels\"].argmax(dim=-1)\n\n    # Flatten for metrics\n    pred_flat = pred_ids.view(-1).cpu().numpy()\n    true_flat = true_ids.view(-1).cpu().numpy()\n    all_pred_ids.extend(pred_flat)\n    all_true_ids.extend(true_flat)\n\n    # Convert to label strings\n    all_pred_texts.extend([model.config.id2label[i] for i in pred_flat])\n    all_true_texts.extend([model.config.id2label[i] for i in true_flat])\nt1_loop = time.time()\nprint(f\"\\nInference & gathering took {t1_loop - t0_loop:.2f}s\")\n\n# 8. Classification metrics\nt0_cls = time.time()\naccuracy  = accuracy_score(all_true_ids, all_pred_ids)\nprecision = precision_score(all_true_ids, all_pred_ids, average=\"macro\", zero_division=0)\nrecall    = recall_score(all_true_ids, all_pred_ids, average=\"macro\", zero_division=0)\nf1        = f1_score(all_true_ids, all_pred_ids, average=\"macro\", zero_division=0)\nt1_cls = time.time()\n\nprint(f\"\\nClassification metrics computed in {t1_cls - t0_cls:.2f}s\")\nprint(\"=== Classification Metrics ===\")\nprint(f\"Accuracy      : {accuracy:.4f}\")\nprint(f\"Precision (M) : {precision:.4f}\")\nprint(f\"Recall    (M) : {recall:.4f}\")\nprint(f\"F1 Score  (M) : {f1:.4f}\")\n\n# 9. BERTScore (semantic similarity)\nt0_bert = time.time()\nbert_p, bert_r, bert_f1 = bert_score(\n    all_pred_texts,\n    all_true_texts,\n    lang=\"en\",\n    model_type=\"bert-base-uncased\",\n    rescale_with_baseline=True\n)\nt1_bert = time.time()\nprint(f\"\\nBERTScore computed in {t1_bert - t0_bert:.2f}s\")\nprint(\"=== BERTScore ===\")\nprint(f\"Precision : {bert_p.mean().item():.4f}\")\nprint(f\"Recall    : {bert_r.mean().item():.4f}\")\nprint(f\"F1        : {bert_f1.mean().item():.4f}\")\n\n# 10. BARTScore (semantic entailment)\nt0_bart = time.time()\nbart_scorer = BARTScorer(device=device.type, checkpoint=\"facebook/bart-large-cnn\")\nbart_scores = bart_scorer.score(\n    all_pred_texts,\n    all_true_texts,\n    batch_size=8\n)\nt1_bart = time.time()\nmean_bart = sum(bart_scores) / len(bart_scores)\nprint(f\"\\nBARTScore computed in {t1_bart - t0_bart:.2f}s\")\nprint(\"=== BARTScore ===\")\nprint(f\"Mean score: {mean_bart:.4f}\")\n\n# --- End overall timer ---\nt1_overall = time.time()\nprint(f\"\\nTotal evaluation time: {t1_overall - t0_overall:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:01:04.290932Z","iopub.execute_input":"2025-05-14T06:01:04.291671Z","iopub.status.idle":"2025-05-14T06:03:27.909387Z","shell.execute_reply.started":"2025-05-14T06:01:04.291642Z","shell.execute_reply":"2025-05-14T06:03:27.908705Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Evaluating batches: 100%|██████████| 223/223 [01:53<00:00,  1.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nInference & gathering took 113.86s\n\nClassification metrics computed in 0.02s\n=== Classification Metrics ===\nAccuracy      : 0.6796\nPrecision (M) : 0.1208\nRecall    (M) : 0.1220\nF1 Score  (M) : 0.1090\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"350042b22fcf4475bd4d7f7af4463a09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55983b5c184f4937b8dd356839b3680e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4494da4fc5140dd962a8273f9f6e152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b808599c516447fb8c7f2f1c971e530b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cac024c388848fabb21ffee4647b54c"}},"metadata":{}},{"name":"stdout","text":"\nBERTScore computed in 7.16s\n=== BERTScore ===\nPrecision : 0.8412\nRecall    : 0.8376\nF1        : 0.8382\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387d8bedd9b74a2b86849bf796f805a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d9ad107d5eb47dca1ca5e8c33e0a0dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c65e642e1f44557a3c0913b2b660a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf58e190768f4084aee70eacb1874f35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515b61aafb84433d8243cce9805e7b2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d3bd72021b94a309bd5b7d0f6632663"}},"metadata":{}},{"name":"stdout","text":"\nBARTScore computed in 21.09s\n=== BARTScore ===\nMean score: -3.3844\n\nTotal evaluation time: 142.13s\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import shutil\nimport os\n\nfolder_to_zip = \"/kaggle/working/vilt-lora-manual-best\"\noutput_zip_name = \"/kaggle/working/vilt-lora-manual-best_model\" # Name for the zip file (no .zip here)\n\ntry:\n    shutil.make_archive(output_zip_name,  # The name of the file to create (e.g., /kaggle/working/my_model_archive)\n                        'zip',             # The format (zip, tar, etc.)\n                        root_dir=os.path.dirname(folder_to_zip), # The directory containing the folder to zip\n                        base_dir=os.path.basename(folder_to_zip)) # The folder to zip\n\n    print(f\"Successfully created zip file: {output_zip_name}.zip\")\n    print(f\"You can now find '{os.path.basename(output_zip_name)}.zip' in the Output section on the right sidebar (or under /kaggle/working/) and download it.\")\nexcept FileNotFoundError:\n    print(f\"Error: The folder {folder_to_zip} was not found. Please check the path.\")\nexcept Exception as e:\n    print(f\"An error occurred during zipping: {e}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:04:12.264944Z","iopub.execute_input":"2025-05-14T06:04:12.265469Z","iopub.status.idle":"2025-05-14T06:04:13.560566Z","shell.execute_reply.started":"2025-05-14T06:04:12.265432Z","shell.execute_reply":"2025-05-14T06:04:13.559782Z"}},"outputs":[{"name":"stdout","text":"Successfully created zip file: /kaggle/working/vilt-lora-manual-best_model.zip\nYou can now find 'vilt-lora-manual-best_model.zip' in the Output section on the right sidebar (or under /kaggle/working/) and download it.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Define the output zip file name\nzip_filename = '/kaggle/working/output.zip'\n\n# List of files and directories to include\nitems_to_zip = [\n    'vilt-lora-manual-best',\n    'README.md',\n    'adapter_config.json',\n    'adapter_model.safetensors'\n]\n\ndef zip_directory(path, ziph):\n    # Walk through all files in the directory\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Add file to zip file, preserving directory structure\n            ziph.write(file_path, os.path.relpath(file_path, os.path.dirname(path)))\n\nwith zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.isdir(item):\n            # Add directory recursively\n            zip_directory(item, zipf)\n        elif os.path.isfile(item):\n            # Add single file\n            zipf.write(item)\n            \nprint(f\"Zip file created at: {zip_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T04:06:39.277565Z","iopub.execute_input":"2025-05-11T04:06:39.278121Z","iopub.status.idle":"2025-05-11T04:06:40.689480Z","shell.execute_reply.started":"2025-05-11T04:06:39.278095Z","shell.execute_reply":"2025-05-11T04:06:40.688607Z"}},"outputs":[{"name":"stdout","text":"Zip file created at: /kaggle/working/output.zip\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!ls -lh /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T04:05:59.955774Z","iopub.execute_input":"2025-05-11T04:05:59.956502Z","iopub.status.idle":"2025-05-11T04:06:00.113549Z","shell.execute_reply.started":"2025-05-11T04:05:59.956480Z","shell.execute_reply":"2025-05-11T04:06:00.112505Z"}},"outputs":[{"name":"stdout","text":"total 25M\ndrwxr-xr-x 2 root root 4.0K May 10 18:08 vilt-lora-manual-best\n-rw-r--r-- 1 root root  25M May 11 03:58 vilt-lora-manual-best_model.zip\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"exit()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-11T04:08:54.653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}