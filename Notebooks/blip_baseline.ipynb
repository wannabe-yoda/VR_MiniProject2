{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11793402,"sourceType":"datasetVersion","datasetId":7405384}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForQuestionAnswering\nfrom PIL import Image\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom transformers import pipeline  # For BARTScore\n\n# Install BERTScore (if not already installed)\n!pip install bert-score\n\nfrom bert_score import score as bert_score\n\n# Check if GPU is available and set the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"Using CPU\")\n\n# Load the BLIP processor and model, move to GPU\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n\nimport pandas as pd\n\n# Load your data\ncsv_path = \"/kaggle/input/vr-final-project-baseline/VR_Final_Project/Dataset/qna_final.csv\"\ndf = pd.read_csv(csv_path)\n\n# Get unique Item_IDs from the DataFrame\nunique_ids = df['Item_ID'].unique()\n\n# Select the first 20 unique Item_IDs\nfirst_20_unique_ids = unique_ids[:20]\n\n# Create a new DataFrame containing the first occurrence of each of these 20 unique Item_IDs\ndf_20_unique_rows = df[df['Item_ID'].isin(first_20_unique_ids)].drop_duplicates(subset=['Item_ID'], keep='first').head(20).copy()\n\n# Reset the index of the new DataFrame\ndf_20_unique_rows = df_20_unique_rows.reset_index(drop=True)\n\n# Print the new DataFrame to verify\nprint(df.head())\nprint(df_20_unique_rows.head())\n\n\n# Check the number of rows and unique Item_IDs in the new DataFrame\nprint(f\"\\nNumber of rows in df_20_unique_rows: {len(df_20_unique_rows)}\")\nprint(f\"Number of unique Item_IDs in df_20_unique_rows: {df_20_unique_rows['Item_ID'].nunique()}\")\n\n# If you want to work with this smaller DataFrame instead of the original 'df',\n# you can replace 'df' with 'df_20_unique_rows' in the subsequent code.\n#df = df_20_unique_rows # changed df here\n\n# Split data into train and test sets\nunique_ids = df[\"Item_ID\"].unique()\nprint(unique_ids)\nrandom_seed = 42\nnp.random.seed(random_seed)\ntrain_ids, temp_ids = train_test_split(unique_ids, test_size=0.3, random_state=random_seed)\nval_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=random_seed)\ntrain_df = df[df[\"Item_ID\"].isin(train_ids)]\nval_df = df[df[\"Item_ID\"].isin(val_ids)]\ntest_df = df[df[\"Item_ID\"].isin(test_ids)]\n\nprint(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n# Image directory and path function\nimage_dir = \"/kaggle/input/vr-final-project-baseline/VR_Final_Project/Dataset/extracted/images/small\"\ndef get_relative_path(full_path):\n    parts = full_path.split('/')\n    return f\"{parts[-2]}/{parts[-1]}\" if len(parts) >= 2 else full_path\n\n# Function to get predictions\ndef predict_answers(image_paths, questions):\n    predicted_answers = []\n    for img_path, question in zip(image_paths, questions):\n        relative_path = get_relative_path(img_path)\n        full_image_path = f\"{image_dir}/{relative_path}\"\n        try:\n            image = Image.open(full_image_path).convert(\"RGB\")\n        except FileNotFoundError:\n            print(f\"Error: Image not found at {full_image_path} (from original: {img_path})\")\n            predicted_answers.append(None)\n            continue\n\n        inputs = processor(images=image, text=question, return_tensors=\"pt\").to(device) # Move inputs to GPU\n        with torch.no_grad():\n            outputs = model.generate(**inputs)\n        answer = processor.decode(outputs[0], skip_special_tokens=True).strip()\n        predicted_answers.append(answer)\n    return predicted_answers\n# Get predictions for the test set\ntest_image_paths = [f\"{image_dir}/{get_relative_path(path)}\" for path in test_df['Image_Path']]\ntest_questions = test_df['Question'].tolist()\nground_truth_answers = test_df['Answer'].tolist()\npredicted_answers = predict_answers(test_image_paths, test_questions)\n# --- Evaluate Metrics ---\n\n# 1. Accuracy\npredicted_answers_lower = [ans.lower() if ans is not None else \"\" for ans in predicted_answers] # Handle None predictions\nground_truth_answers_lower = [ans.lower() for ans in ground_truth_answers]\naccuracy = accuracy_score(ground_truth_answers_lower, predicted_answers_lower)\nprint(f\"Baseline Accuracy: {accuracy:.4f}\")\n\n# 2. F1 Score\n# For F1 score, we need to consider how to handle multiple possible \"classes\" (unique answers).\n# We'll calculate a micro-averaged F1 score, treating each answer as a class.\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(ground_truth_answers_lower)  # Fit on ground truth *first*\nencoded_ground_truth = label_encoder.transform(ground_truth_answers_lower)\ntry:\n    encoded_predicted = label_encoder.transform(predicted_answers_lower) # Then transform predictions\nexcept ValueError as e:\n    print(f\"Error encoding predictions: {e}\")\n    encoded_predicted = np.zeros_like(encoded_ground_truth)  # Or handle it in a way that makes sense for your task\nf1 = f1_score(encoded_ground_truth, encoded_predicted, average='micro')\nprint(f\"Baseline F1 Score (Micro): {f1:.4f}\")\n\n# 3. BARTScore\n# Load the BARTScore model\n#bartscore_pipeline = pipeline(\"bart-score\", model=\"facebook/bart-large-cnn\", device=device) # Move pipeline to GPU\n# Calculate BARTScore (takes a list of predicted and a list of ground truth)\nif all(predicted_answers) and all(ground_truth_answers):\n    bart_scores = bert_score(predicted_answers, ground_truth_answers, model_type='facebook/bart-large-cnn',  device=device)\n    avg_bart_score = sum(bart_scores[0].tolist()) / len(bart_scores[0])\n    print(f\"Baseline BARTScore: {avg_bart_score:.4f}\")\nelse:\n    print(\"Skipping BARTScore calculation due to missing predictions.\")\n\n# 4. BERTScore\n# Calculate BERTScore\nif all(predicted_answers) and all(ground_truth_answers):\n    P, R, F1 = bert_score(predicted_answers, ground_truth_answers, lang=\"en\", verbose=True, device=device) # Move calculation to GPU\n    avg_bert_f1 = F1.mean().item()\n    print(f\"Baseline BERTScore F1: {avg_bert_f1:.4f}\")\nelse:\n    print(\"Skipping BERTScore calculation due to missing predictions.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T05:57:01.285311Z","iopub.execute_input":"2025-05-14T05:57:01.285595Z","iopub.status.idle":"2025-05-14T06:03:28.195820Z","shell.execute_reply.started":"2025-05-14T05:57:01.285574Z","shell.execute_reply":"2025-05-14T06:03:28.195018Z"}},"outputs":[{"name":"stderr","text":"2025-05-14 05:57:06.422598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747202226.444667      89 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747202226.451386      89 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"Using GPU: Tesla T4\n      Image_ID     Item_ID                   Question Answer       Image_Path\n0  81mEuveXFVL  B07PW6XQY8  What is the bed's finish?  Wenge  c3/c339ab63.jpg\n1  81mEuveXFVL  B07PW6XQY8  What is the bed's finish?  Wenge  a1/a19ec002.jpg\n2  81mEuveXFVL  B07PW6XQY8  What is the bed's finish?  Wenge  b0/b022e37b.jpg\n3  81mEuveXFVL  B07PW6XQY8  What is the bed's finish?  Wenge  23/23063c20.jpg\n4  81mEuveXFVL  B07PW6XQY8  What is the bed's finish?  Wenge  15/15dd91bd.jpg\n      Image_ID     Item_ID                                           Question  \\\n0  81mEuveXFVL  B07PW6XQY8                          What is the bed's finish?   \n1  61mZ+WX+N8L  B074VDJ7KZ                          Is this product unsalted?   \n2  51JKXD3XTJL  B00004SD6V                           Is the trowel rustproof?   \n3  41ZZFRX9TXL  B00005041B             What is the shape of the light shades?   \n4  51jNv-Fzw6L  B000GXF4UC  What is the color of the Strathwood Camano Sun...   \n\n  Answer       Image_Path  \n0  Wenge  c3/c339ab63.jpg  \n1     No  c2/c268441e.jpg  \n2    Yes  44/448ff753.jpg  \n3   Owls  d1/d1aed412.jpg  \n4  Brown  52/520c09d3.jpg  \n\nNumber of rows in df_20_unique_rows: 20\nNumber of unique Item_IDs in df_20_unique_rows: 20\n['B07PW6XQY8' 'B074VDJ7KZ' 'B00004SD6V' ... 'B078W5Q4ZP' 'B078WRPMMB'\n 'B078WVB53N']\nTrain size: 19693, Val size: 4282, Test size: 3979\nBaseline Accuracy: 0.4871\nError encoding predictions: y contains previously unseen labels: '4'\nBaseline F1 Score (Micro): 0.0010\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e87116fba04c628b90b80edcad1cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f66153e39747e9ab94be89a1b76937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b2b890f3924d86aa028997c8fe4ffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205e2161a9364ea4945fa20cf789d45e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f8b859bb88243a58c768be1d7838634"}},"metadata":{}},{"name":"stdout","text":"Baseline BARTScore: 0.6892\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e554908ff92a47fcb57059c47a56dc78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"940a949c5dc04041944f7560f02d9ce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"691f15d02f014bd89e605445ed2aed8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4fe0a5d2e224399909fe603f636a6dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4811a0553d4542629968a50a09089b11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2fbdacab2794c84b0f8f5286aff3478"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ab5f383e864e70b18ea166a13a14b5"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37103591133b4f87b5036d05c0a609e1"}},"metadata":{}},{"name":"stdout","text":"done in 1.38 seconds, 2882.65 sentences/sec\nBaseline BERTScore F1: 0.9675\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#storing the test_df, train_df and val_df for future references\n# Assuming 'df' is your DataFrame\ntest_df.to_csv('test_qna_final.csv', index=False)\ntrain_df.to_csv('train_qna_final.csv', index=False)\nval_df.to_csv('val_qna_final.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T06:04:00.959678Z","iopub.execute_input":"2025-05-14T06:04:00.960334Z","iopub.status.idle":"2025-05-14T06:04:01.053851Z","shell.execute_reply.started":"2025-05-14T06:04:00.960309Z","shell.execute_reply":"2025-05-14T06:04:01.053315Z"}},"outputs":[],"execution_count":2}]}